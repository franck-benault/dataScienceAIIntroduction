{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d83a1db-49cb-4e6b-9571-873b56a73981",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f768c-d109-476d-8ba7-3fa767aeb31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiding the warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1a8d7-1329-414d-aaab-74f9f4d25e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the version of the lbraries\n",
    "# base libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# diagram libraries\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# machine learning libraries\n",
    "import sklearn\n",
    "import nltk\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de46af91-64e6-4901-a565-b6adc08063fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# N-Gram examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd1bb1-7fff-432e-b90e-88926d52a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "from nltk import bigrams, trigrams\n",
    "from nltk.corpus import reuters\n",
    "from collections import defaultdict\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenize the text\n",
    "words = nltk.word_tokenize(' '.join(reuters.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1731f4-f84f-4117-95bf-815774109a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trigrams\n",
    "bi_grams = list(bigrams(words))\n",
    "\n",
    "# Build a trigram model\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "# Count frequency of co-occurrence\n",
    "for w1, w2 in bi_grams:\n",
    "    model[(w1)][w2] += 1\n",
    "\n",
    "# Transform the counts into probabilities\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count\n",
    "\n",
    "# Function to predict the next word\n",
    "def predict_next_wordB(w1):\n",
    "    \"\"\"\n",
    "    Predicts the next word based on the previous two words using the trained trigram model.\n",
    "    Args:\n",
    "    w1 (str): The first word.\n",
    "    w2 (str): The second word.\n",
    "\n",
    "    Returns:\n",
    "    str: The predicted next word.\n",
    "    \"\"\"\n",
    "    next_word = model[w1]\n",
    "    if next_word:\n",
    "        predicted_word = max(next_word, key=next_word.get)  # Choose the most likely next word\n",
    "        return predicted_word\n",
    "    else:\n",
    "        return \"No prediction available\"\n",
    "\n",
    "# Example usage\n",
    "first='This'\n",
    "print(first)\n",
    "sentence = first\n",
    "next=predict_next_wordB(first)\n",
    "while((next!='No prediction available') and (next!='.')):\n",
    "    print(next)\n",
    "    sentence =sentence+' '+next\n",
    "    next=predict_next_wordB(next)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada9dc5-6c48-422f-8d73-ab75e2a90861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "words = nltk.word_tokenize(' '.join(reuters.words()))\n",
    "\n",
    "# Create trigrams\n",
    "tri_grams = list(trigrams(words))\n",
    "\n",
    "# Build a trigram model\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "# Count frequency of co-occurrence\n",
    "for w1, w2, w3 in tri_grams:\n",
    "    model[(w1, w2)][w3] += 1\n",
    "\n",
    "# Transform the counts into probabilities\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count\n",
    "\n",
    "# Function to predict the next word\n",
    "def predict_next_wordT(w1, w2):\n",
    "    \"\"\"\n",
    "    Predicts the next word based on the previous two words using the trained trigram model.\n",
    "    Args:\n",
    "    w1 (str): The first word.\n",
    "    w2 (str): The second word.\n",
    "\n",
    "    Returns:\n",
    "    str: The predicted next word.\n",
    "    \"\"\"\n",
    "    next_word = model[w1, w2]\n",
    "    if next_word:\n",
    "        predicted_word = max(next_word, key=next_word.get)  # Choose the most likely next word\n",
    "        return predicted_word\n",
    "    else:\n",
    "        return \"No prediction available\"\n",
    "\n",
    "# Example usage\n",
    "first='This'\n",
    "second='is'\n",
    "sentence = first+' '+second\n",
    "next=predict_next_wordT(first,second)\n",
    "while((next!='No prediction available') and (next!='.')):\n",
    "    sentence =sentence+' '+next\n",
    "    first=second\n",
    "    second=next\n",
    "    next=predict_next_wordT(first,second)\n",
    "    #print(next)\n",
    "print(sentence)\n",
    "\n",
    "first='That'\n",
    "second='was'\n",
    "sentence = first+' '+second\n",
    "next=predict_next_wordT(first,second)\n",
    "while((next!='No prediction available') and (next!='.')):\n",
    "    sentence =sentence+' '+next\n",
    "    first=second\n",
    "    second=next\n",
    "    next=predict_next_wordT(first,second)\n",
    "    #print(next)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75939ee-89e4-4696-8568-4defe9521241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
